#!/usr/bin/env bash

#
# Set Hadoop-specific environment variables here.
#
# Created by Chef -- changes will be overwritten
#

# a fence, because bin/hadoop sources this like four times
this_file="`readlink -f $BASH_SOURCE`"
if [ "$HADOOP_ENV_SOURCED" == "" ] || [ "$HADOOP_ENV_SOURCED" != "$this_file" ] ; then

#
# Locations
#
export HADOOP_HOME=/home/ubuntu/hadoop/hadoop-0.23.0
export HADOOP_CONF_DIR=/home/ubuntu/hadoop/hadoop-0.23.0/conf
#export HADOOP_SLAVES=${HADOOP_HOME}/conf/slaves

export HADOOP_IDENT_STRING=hadoop
export HADOOP_NODENAME="hadoop_demo-master-0"

#
# Java Options
#

# The java implementation to use.  Required.
export JAVA_HOME=/usr/lib/jvm/java-6-sun/jre

# Extra classpaths for hadoop
export HADOOP_CLASSPATH=":$HADOOP_CLASSPATH"

# Extra Java runtime options.  Empty by default.
if [ "$HADOOP_OPTS" == "" ]; then export HADOOP_OPTS="-server"; else HADOOP_OPTS+=" -server"; fi

# Ubuntu wants us to use IPv6. Hadoop doesn't support that, but nevertheless binds to :::50010. Let's tell it we don't agree.
export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true"

# JVM options
# -XX: The maximum amount of heap to use, in MB. Default is 1000.
export               HADOOP_HEAPSIZE="1000" # no 'm'
export          HADOOP_NAMENODE_OPTS="-XX:+UseParallelGC -Xmx1000m $HADOOP_NAMENODE_OPTS"
export HADOOP_SECONDARYNAMENODE_OPTS="-XX:+UseParallelGC -Xmx1000m $HADOOP_SECONDARYNAMENODE_OPTS"
export        HADOOP_JOBTRACKER_OPTS="-XX:+UseParallelGC -Xmx1000m $HADOOP_JOBTRACKER_OPTS"
export          HADOOP_DATANODE_OPTS="-XX:+UseParallelGC -Xmx1000m $HADOOP_DATANODE_OPTS"
export       HADOOP_TASKTRACKER_OPTS="-XX:+UseParallelGC -Xmx1000m $HADOOP_TASKTRACKER_OPTS"

# JMX monitoring -- see http://www.cloudera.com/blog/2009/03/hadoop-metrics/
export                   HADOOP_OPTS="-Djava.rmi.server.hostname=10.112.126.26 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false $HADOOP_OPTS"
export          HADOOP_NAMENODE_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8004 $HADOOP_NAMENODE_OPTS"
export HADOOP_SECONDARYNAMENODE_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8005 $HADOOP_SECONDARYNAMENODE_OPTS"
export        HADOOP_JOBTRACKER_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port= $HADOOP_JOBTRACKER_OPTS"
export          HADOOP_DATANODE_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8006 $HADOOP_DATANODE_OPTS"
export       HADOOP_TASKTRACKER_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port= $HADOOP_TASKTRACKER_OPTS"
export          HADOOP_BALANCER_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8007 $HADOOP_BALANCER_OPTS"

#
# Other
#

# The following applies to multiple commands (fs, dfs, fsck, distcp etc)
# export HADOOP_CLIENT_OPTS

# Extra ssh options.  Empty by default.
export HADOOP_SSH_OPTS="-o StrictHostKeyChecking=no"

# Seconds to sleep between slave commands.  Unset by default.  This
# can be useful in large clusters, where, e.g., slave rsyncs can
# otherwise arrive faster than the master can service them.
# export HADOOP_SLAVE_SLEEP=0.1

# The scheduling priority for daemon processes.  See 'man nice'.
# export HADOOP_NICENESS=10

# double-run fence end
export HADOOP_ENV_SOURCED="$this_file"
fi
